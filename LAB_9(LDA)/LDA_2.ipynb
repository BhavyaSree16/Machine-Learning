{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import the libraries**"
      ],
      "metadata": {
        "id": "08W3KZYjLLxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "i-w5pRCxLO6p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Dataset**"
      ],
      "metadata": {
        "id": "bjf_PfFyLZe0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3PlLry3ASJ7",
        "outputId": "e2fcf9c4-b1a8-46a0-bede-41d9869c4a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Wine Dataset Loaded\n",
            "Number of Features: 13\n",
            "Number of Classes: 3\n",
            "Feature Data (first 5 rows):\n",
            "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
            "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
            "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
            "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
            "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
            "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
            "\n",
            "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
            "0        3.06                  0.28             2.29             5.64  1.04   \n",
            "1        2.76                  0.26             1.28             4.38  1.05   \n",
            "2        3.24                  0.30             2.81             5.68  1.03   \n",
            "3        3.49                  0.24             2.18             7.80  0.86   \n",
            "4        2.69                  0.39             1.82             4.32  1.04   \n",
            "\n",
            "   od280/od315_of_diluted_wines  proline  \n",
            "0                          3.92   1065.0  \n",
            "1                          3.40   1050.0  \n",
            "2                          3.17   1185.0  \n",
            "3                          3.45   1480.0  \n",
            "4                          2.93    735.0  \n",
            "Target Labels (first 5):\n",
            " [0 0 0 0 0]\n",
            "Class Names: ['class_0' 'class_1' 'class_2']\n"
          ]
        }
      ],
      "source": [
        "# Load the Wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X = wine.data  # Features\n",
        "y = wine.target  # Labels\n",
        "target_names = wine.target_names  # Class names\n",
        "\n",
        "# Display the dataset information\n",
        "print(\"Step 1: Wine Dataset Loaded\")\n",
        "print(\"Number of Features:\", X.shape[1])\n",
        "print(\"Number of Classes:\", len(target_names))\n",
        "print(\"Feature Data (first 5 rows):\\n\", pd.DataFrame(X, columns=wine.feature_names).head())\n",
        "print(\"Target Labels (first 5):\\n\", y[:5])\n",
        "print(\"Class Names:\", target_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the Data**\n"
      ],
      "metadata": {
        "id": "4Fi4DdQSMBpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(\"Training Set Size:\", X_train.shape)\n",
        "print(\"Testing Set Size:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y9bB9lqM3hq",
        "outputId": "25757fc0-8dc8-4847-870b-102ce9bf73e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Size: (124, 13)\n",
            "Testing Set Size: (54, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train LDA Model**"
      ],
      "metadata": {
        "id": "blCjvJ6ZNG7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print(\"\\nStep 3: LDA Model Trained on Training Set\")\n",
        "\n",
        "# Step 4: Evaluate the LDA Model\n",
        "y_pred_lda = lda.predict(X_test)\n",
        "accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
        "precision_lda = precision_score(y_test, y_pred_lda, average='weighted')\n",
        "recall_lda = recall_score(y_test, y_pred_lda, average='weighted')\n",
        "confusion_lda = confusion_matrix(y_test, y_pred_lda)\n",
        "\n",
        "print(\"\\nStep 4: LDA Model Evaluation\")\n",
        "print(\"LDA Accuracy:\", accuracy_lda)\n",
        "print(\"LDA Precision:\", precision_lda)\n",
        "print(\"LDA Recall:\", recall_lda)\n",
        "print(\"LDA Confusion Matrix:\\n\", confusion_lda)\n",
        "print(\"LDA Classification Report:\\n\", classification_report(y_test, y_pred_lda))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exs8qa90NJqy",
        "outputId": "fb428a14-4cdf-4d24-bb9b-7d1610fd2871"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 3: LDA Model Trained on Training Set\n",
            "\n",
            "Step 4: LDA Model Evaluation\n",
            "LDA Accuracy: 1.0\n",
            "LDA Precision: 1.0\n",
            "LDA Recall: 1.0\n",
            "LDA Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 14]]\n",
            "LDA Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        21\n",
            "           2       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation of Dataset**"
      ],
      "metadata": {
        "id": "HZe41j7INu2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels on the test set\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Compute the model's accuracy\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "\n",
        "# Compute the model's precision\n",
        "precision_log_reg = precision_score(y_test, y_pred_log_reg, average='weighted')\n",
        "\n",
        "# Compute the model's recall\n",
        "recall_log_reg = recall_score(y_test, y_pred_log_reg, average='weighted')\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
        "\n",
        "# Display the evaluation results\n",
        "print(\"\\nLogistic Regression Model Evaluation\")\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_log_reg)\n",
        "print(\"Logistic Regression Precision:\", precision_log_reg)\n",
        "print(\"Logistic Regression Recall:\", recall_log_reg)\n",
        "print(\"Logistic Regression Confusion Matrix:\\n\", confusion_log_reg)\n",
        "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX85jil0Nzyh",
        "outputId": "8960bea5-1123-46de-a6c1-89368eb38a0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Model Evaluation\n",
            "Logistic Regression Accuracy: 1.0\n",
            "Logistic Regression Precision: 1.0\n",
            "Logistic Regression Recall: 1.0\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 14]]\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        21\n",
            "           2       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparision with Logistic Regression**"
      ],
      "metadata": {
        "id": "ATKtJngzOy0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=10000)  # Increase max_iter if convergence warning occurs\n",
        "log_reg.fit(X_train, y_train)\n",
        "print(\"\\nStep 5: Logistic Regression Model Trained on Training Set\")\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics for Logistic Regression\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "precision_log_reg = precision_score(y_test, y_pred_log_reg, average='weighted')\n",
        "recall_log_reg = recall_score(y_test, y_pred_log_reg, average='weighted')\n",
        "confusion_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
        "\n",
        "# Display the evaluation results for Logistic Regression\n",
        "print(\"\\nLogistic Regression Model Evaluation\")\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_log_reg)\n",
        "print(\"Logistic Regression Precision:\", precision_log_reg)\n",
        "print(\"Logistic Regression Recall:\", recall_log_reg)\n",
        "print(\"Logistic Regression Confusion Matrix:\\n\", confusion_log_reg)\n",
        "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Step 6: Compare with LDA\n",
        "# Assuming lda is already trained and the evaluation metrics are defined from previous steps\n",
        "\n",
        "# Print summary of comparisons\n",
        "print(\"\\nSummary of Comparison with LDA:\")\n",
        "print(f\"LDA Accuracy: {accuracy_lda:.2f}, Logistic Regression Accuracy: {accuracy_log_reg:.2f}\")\n",
        "print(f\"LDA Precision: {precision_lda:.2f}, Logistic Regression Precision: {precision_log_reg:.2f}\")\n",
        "print(f\"LDA Recall: {recall_lda:.2f}, Logistic Regression Recall: {recall_log_reg:.2f}\")\n",
        "\n",
        "# You can also compare the confusion matrices for both models\n",
        "print(\"\\nLDA Confusion Matrix:\\n\", confusion_lda)\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\\n\", confusion_log_reg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxm3phncOygZ",
        "outputId": "f1271159-b0a1-4f3a-bc33-f1a56d9a494d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Logistic Regression Model Trained on Training Set\n",
            "\n",
            "Logistic Regression Model Evaluation\n",
            "Logistic Regression Accuracy: 1.0\n",
            "Logistic Regression Precision: 1.0\n",
            "Logistic Regression Recall: 1.0\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 14]]\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        21\n",
            "           2       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n",
            "\n",
            "Summary of Comparison with LDA:\n",
            "LDA Accuracy: 1.00, Logistic Regression Accuracy: 1.00\n",
            "LDA Precision: 1.00, Logistic Regression Precision: 1.00\n",
            "LDA Recall: 1.00, Logistic Regression Recall: 1.00\n",
            "\n",
            "LDA Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 14]]\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 14]]\n"
          ]
        }
      ]
    }
  ]
}